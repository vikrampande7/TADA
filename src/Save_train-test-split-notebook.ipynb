{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa06b93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Calculating features!\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "(36, 42)\n",
      "Saving train-validation-test sequences and labels\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from pickle import dump\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Preprocessing import scale_features\n",
    "from Preprocessing import create_features\n",
    "\n",
    "np.random.seed(1258)  # for reproducibility\n",
    "save_file_path = '../data/split-train-val-test/'\n",
    "if not os.path.exists(save_file_path):\n",
    "     os.mkdir(save_file_path)\n",
    "\n",
    "'''\n",
    "Data contains two datasets\n",
    "\n",
    "'''\n",
    "print('Loading data')\n",
    "with open('../data/TrainingsDataV2.csv', 'r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    data = []\n",
    "    for i in csv_reader:\n",
    "        data.append([i[0], i[1], i[2], i[3], i[4]])\n",
    "data.pop(0)\n",
    "\n",
    "sequences = [i[2] for i in data]\n",
    "data = np.array(data)\n",
    "y0 = np.double(data[:, 4])\n",
    "y = np.column_stack([y0, 1 - y0])\n",
    "\n",
    "'''\n",
    "Calculating 42 features\n",
    "Splitting into train, validation, and test set\n",
    "\n",
    "'''\n",
    "# Defines the sequence window size and steps (stride length). Changing these is as easy as changing their values.\n",
    "SEQUENCE_WINDOW = 5\n",
    "STEPS = 1\n",
    "LENGTH = 40\n",
    "\n",
    "#Calculate features\n",
    "print('Calculating features!')\n",
    "features = create_features(sequences, SEQUENCE_WINDOW, STEPS, LENGTH)\n",
    "\n",
    "# Save the features and activation scores\n",
    "dump(features, open('features_OnlyPlants.pkl', 'wb'))\n",
    "\n",
    "# Split sequences in training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, y, random_state = 42, test_size=0.1, stratify = y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state = 42, test_size=0.22, stratify = y_train)\n",
    "\n",
    "# Scale features\n",
    "X_train_scaled = scale_features(X_train)\n",
    "X_test_scaled = scale_features(X_test)\n",
    "X_val_scaled = scale_features(X_val)\n",
    "print(X_train_scaled[0].shape)\n",
    "\n",
    "print('Saving train-validation-test sequences and labels')\n",
    "np.savez_compressed(save_file_path + 'train-features-scaled.npz', X_train_scaled)\n",
    "np.savez_compressed(save_file_path + 'train-labels.npz', y_train)\n",
    "\n",
    "np.savez_compressed(save_file_path + 'validation-features-scaled.npz', X_val_scaled)\n",
    "np.savez_compressed(save_file_path + 'validation-labels.npz', y_val)\n",
    "\n",
    "np.savez_compressed(save_file_path + 'test-features-scaled.npz', X_test_scaled)\n",
    "np.savez_compressed(save_file_path + 'test-labels.npz', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5f7219a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protfasta\n",
      "  Downloading protfasta-0.1.12.tar.gz (142 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.6/142.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: protfasta\n",
      "  Building wheel for protfasta (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for protfasta: filename=protfasta-0.1.12-py3-none-any.whl size=120135 sha256=bf438f72f987c8213029c346b8aa18946607342671e69c425d83788c14b6d77d\n",
      "  Stored in directory: /home/vspande/.cache/pip/wheels/f8/bd/7f/79ade79ffe632ddc2a8c5962f952b7b8712b6403de165f46cc\n",
      "Successfully built protfasta\n",
      "Installing collected packages: protfasta\n",
      "Successfully installed protfasta-0.1.12\n"
     ]
    }
   ],
   "source": [
    "!pip install protfasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbd527e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
